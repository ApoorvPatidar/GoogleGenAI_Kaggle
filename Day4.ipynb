{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2043cd76",
   "metadata": {},
   "source": [
    "## Fine Tuning a Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fffcb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19f0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key = GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "370cf643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.5-flash-001-tuning\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "    if model.supported_actions and \"createTunedModel\" in model.supported_actions:\n",
    "        print(model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe9ddfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
    "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
    "\n",
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f4a50a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c31d0",
   "metadata": {},
   "source": [
    "Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "419b9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_newsgroup_row(data):\n",
    "    msg = email.message_from_string(data)\n",
    "    text = f\"{msg['Subject']}\\n\\n{msg.get_payload()}\"\n",
    "    text = re.sub(r\"[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "    text = text[:40000]\n",
    "\n",
    "    return text\n",
    "\n",
    "def preprocess_newsgroup_data(newsgroup_dataset):\n",
    "    df = pd.DataFrame({\n",
    "        \"Text\": newsgroup_dataset.data,\n",
    "        \"Label\": newsgroup_dataset.target\n",
    "    })\n",
    "\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_newsgroup_row)\n",
    "    df[\"Class Name\"] = df['Label'].map(lambda l: newsgroup_dataset.target_names[l])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5f8cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHAT car is this!?\\n\\n I was wondering if anyo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI Clock Poll - Final Call\\n\\nA fair number of...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PB questions...\\n\\nwell folks, my mac plus fin...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Shuttle Launch Question\\n\\nFrom article &lt;&gt;...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  WHAT car is this!?\\n\\n I was wondering if anyo...      7   \n",
       "1  SI Clock Poll - Final Call\\n\\nA fair number of...      4   \n",
       "2  PB questions...\\n\\nwell folks, my mac plus fin...      4   \n",
       "3  Re: Weitek P9000 ?\\n\\nRobert J.C. Kyanko () wr...      1   \n",
       "4  Re: Shuttle Launch Question\\n\\nFrom article <>...     14   \n",
       "\n",
       "              Class Name  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = preprocess_newsgroup_data(newsgroups_train)\n",
    "df_test = preprocess_newsgroup_data(newsgroups_test)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "017ac126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(df, num_samples, classes_to_keep):\n",
    "    df = (df.groupby(\"Label\")[df.columns].apply(lambda x: x.sample(num_samples)).reset_index(drop=True))\n",
    "    df = df[df[\"Class Name\"].str.contains(classes_to_keep)]\n",
    "    df[\"Class Name\"] = df[\"Class Name\"].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "TRAIN_NUM_SAMPLES = 50\n",
    "TEST_NUM_SAMPLES = 10\n",
    "CLASSES_TO_KEEP = \"^rec|^sci\"\n",
    "\n",
    "df_train = sample_data(df_train, TRAIN_NUM_SAMPLES, CLASSES_TO_KEEP)\n",
    "df_test = sample_data(df_test, TEST_NUM_SAMPLES, CLASSES_TO_KEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ed04ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need info on 88-89 Bonneville\n",
      "\n",
      "\n",
      " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
      "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
      "differences are far as features or performance. I am also curious to\n",
      "know what the book value is for prefereably the 89 model. And how much\n",
      "less than book value can you usually get them for. In other words how\n",
      "much are they in demand this time of year. I have heard that the mid-spring\n",
      "early summer is the best time to buy.\n",
      "\n",
      "\t\t\tNeil Gandler\n",
      "\n",
      "---\n",
      "Label: rec.autos\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "sample_row = preprocess_newsgroup_row(newsgroups_test.data[sample_idx])\n",
    "sample_label = newsgroups_test.target_names[newsgroups_test.target[sample_idx]]\n",
    "\n",
    "print(sample_row)\n",
    "print('---')\n",
    "print('Label:', sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8908e5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're right, the 1988-1989 Bonneville lineup can be a bit confusing! Here's a breakdown of the trims and their differences, plus some info on values:\n",
      "\n",
      "**1988-1989 Bonneville Trim Levels**\n",
      "\n",
      "* **Base Bonneville:** This was the entry-level model, offering basic features like a 3.8L V6 engine, cloth upholstery, and minimal options. \n",
      "* **LE (Luxury Edition):** The LE added features like a more luxurious interior, power accessories, and a slightly more powerful engine (possibly the 3.8L Turbo V6). \n",
      "* **SE (Special Edition):**  The SE was a sportier trim with unique styling elements, usually a slightly firmer suspension, and possibly the Turbo V6.\n",
      "* **LSE (Luxury Special Edition):**  The LSE combined the luxury features of the LE with the sportiness of the SE, offering a plush interior and a more powerful engine (likely the Turbo V6). \n",
      "* **SSE (Sport Sedan Edition):**  The SSE was the top-of-the-line performance model. It came standard with the Turbo V6, a sport-tuned suspension, and additional performance upgrades.  \n",
      "* **SSEi (Sport Sedan Edition, Injected):** This was a rare and highly sought-after version of the SSE. It featured a fuel-injected version of the Turbo V6, offering even better performance.\n",
      "\n",
      "**Value and Demand**\n",
      "\n",
      "The 1989 Bonneville, especially in good condition, can still command decent value. However, it's a classic car, and values depend heavily on a number of factors:\n",
      "\n",
      "* **Condition:** Pristine, low-mileage examples will fetch the most. Rust, mechanical issues, and wear and tear will significantly reduce value.\n",
      "* **Trim Level:** SSEi models are the most valuable, followed by SSEs, then other trims. \n",
      "* **Mileage:** Lower mileage is always better.\n",
      "* **Market Demand:**  Demand fluctuates. The best time to buy may indeed be in the spring and early summer when inventory is higher and sellers might be more motivated.\n",
      "\n",
      "**Book Value**\n",
      "\n",
      "* **Kelley Blue Book (KBB) and Edmunds:** These websites provide online estimates for used vehicles.  You can get a general idea of book value based on condition, mileage, and location.\n",
      "* **Classic Car Auction Results:** Websites like Bring a Trailer and Mecum Auctions can offer insights into recent sales prices of similar models.\n",
      "\n",
      "**Negotiating Price**\n",
      "\n",
      "* **Expect to pay less than book value:**  It's common to negotiate down from the book value, especially in a buyer's market. \n",
      "* **Research Similar Vehicles:** Check comparable cars listed online and at local dealerships. \n",
      "* **Condition is Key:** The better the condition, the closer you'll be to book value.\n",
      "\n",
      "**Additional Tips:**\n",
      "\n",
      "* **Be Patient:** Take your time to find the right car.\n",
      "* **Get a Pre-Purchase Inspection:**  A mechanic can identify any hidden problems before you buy. \n",
      "* **Financing Options:**  Research financing options before you start shopping.\n",
      "\n",
      "**In Conclusion**\n",
      "\n",
      "The 1989 Bonneville, especially the SSEi, can be a great classic car. However, research is essential to make sure you're getting a good deal.  Good luck in your search! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model = \"gemini-1.5-flash-001\", \n",
    "    contents = sample_row\n",
    "    )\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7e722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While it's impossible to be 100% sure, this message most likely originates from a **Buick or Pontiac-related newsgroup**, possibly one of the following:\n",
      "\n",
      "* **alt.autos.buick**\n",
      "* **rec.autos.buick**\n",
      "* **alt.autos.pontiac**\n",
      "* **rec.autos.pontiac**\n",
      "\n",
      "The message is clearly focused on a specific car model (Bonneville), and the detailed questions about trim levels (LE, SE, LSE, SSE, SSEI) and pricing suggest someone interested in buying a specific vehicle. This makes it highly probable that the message comes from a discussion group dedicated to those brands. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ask the model directly in a zero-shot prompt.\n",
    "\n",
    "prompt = \"From what newsgroup does the following message originate?\"\n",
    "baseline_response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-flash-001\",\n",
    "    contents=[prompt, sample_row])\n",
    "print(baseline_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbf204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos.misc\n",
      "\n",
      "Incorrect.\n"
     ]
    }
   ],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "# You can use a system instruction to do more direct prompting, and get a\n",
    "# more succinct answer.\n",
    "\n",
    "system_instruct = \"\"\"\n",
    "You are a classification service. You will be passed input that represents\n",
    "a newsgroup post and you must respond with the newsgroup from which the post\n",
    "originates.\n",
    "\"\"\"\n",
    "\n",
    "# Define a helper to retry when per-minute quota is reached.\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "# If you want to evaluate your own technique, replace this body of this function\n",
    "# with your model, prompt and other code and return the predicted answer.\n",
    "@retry.Retry(predicate=is_retriable)\n",
    "def predict_label(post: str) -> str:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-1.5-flash-001\",\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=system_instruct),\n",
    "        contents=post)\n",
    "\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Any errors, filters, recitation, etc we can mark as a general error\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        # Clean up the response.\n",
    "        return response.text.strip()\n",
    "\n",
    "\n",
    "prediction = predict_label(sample_row)\n",
    "\n",
    "print(prediction)\n",
    "print()\n",
    "print(\"Correct!\" if prediction == sample_label else \"Incorrect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "210e7da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13e4a5f393248d1b9bd9794aa8d2fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 43.75%\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from tqdm.rich import tqdm as tqdmr\n",
    "import warnings\n",
    "\n",
    "# Enable tqdm features on Pandas.\n",
    "tqdmr.pandas()\n",
    "\n",
    "# But suppress the experimental warning\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n",
    "\n",
    "# Further sample the test data to be mindful of the free-tier quota.\n",
    "df_baseline_eval = sample_data(df_test, 2, '.*')\n",
    "\n",
    "# Make predictions using the sampled data.\n",
    "df_baseline_eval['Prediction'] = df_baseline_eval['Text'].progress_apply(predict_label)\n",
    "\n",
    "# And calculate the accuracy.\n",
    "accuracy = (df_baseline_eval[\"Class Name\"] == df_baseline_eval[\"Prediction\"]).sum() / len(df_baseline_eval)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc814c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: Questions about insurance companies (esp. ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Re: V4 V6 V8 V12 Vx?\\n\\n (The Devil Reincarnat...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re: A Point for Helmet Law is a Point for MC B...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Re: dogs\\n\\n\\n&gt;OOOOOOOpsssss. For a second the...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>alt.fan.dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Football vs. BaseBall (was Game Length )\\n...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stats question\\n\\n\\n\\tI am just wondering whet...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>rec.sports.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NHL PLAYOFF RESULTS FOR GAMES PLAYED 4-22-93\\n...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Re: Why Blues Pulverized Chicago WeenieHawks\\n...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>(error)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Re: Overreacting (was Re: Once tapped, your co...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Re: Tempest\\n\\nIn article &lt;&gt;\\n (Kirill Shklovs...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>(error)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Re: help me, i'm not clever! (how to make powe...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>rec.autos.makers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Re: WD-40 as moisture repellant (was Lead Acid...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>rec.autos.makers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Re: thermogenics\\n\\nIn article &lt;&gt;  (Mark Rober...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>(error)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Re: thermogenics\\n\\nFirst off, if I'm not mist...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>(error)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Re: Gamma Ray Bursters.  WHere  are they.\\n\\nI...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Internet resources\\n\\nI am taking a course ent...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Label  \\\n",
       "0   Re: Questions about insurance companies (esp. ...      7   \n",
       "1   Re: V4 V6 V8 V12 Vx?\\n\\n (The Devil Reincarnat...      7   \n",
       "2   Re: A Point for Helmet Law is a Point for MC B...      8   \n",
       "3   Re: dogs\\n\\n\\n>OOOOOOOpsssss. For a second the...      8   \n",
       "4   Re: Football vs. BaseBall (was Game Length )\\n...      9   \n",
       "5   Stats question\\n\\n\\n\\tI am just wondering whet...      9   \n",
       "6   NHL PLAYOFF RESULTS FOR GAMES PLAYED 4-22-93\\n...     10   \n",
       "7   Re: Why Blues Pulverized Chicago WeenieHawks\\n...     10   \n",
       "8   Re: Overreacting (was Re: Once tapped, your co...     11   \n",
       "9   Re: Tempest\\n\\nIn article <>\\n (Kirill Shklovs...     11   \n",
       "10  Re: help me, i'm not clever! (how to make powe...     12   \n",
       "11  Re: WD-40 as moisture repellant (was Lead Acid...     12   \n",
       "12  Re: thermogenics\\n\\nIn article <>  (Mark Rober...     13   \n",
       "13  Re: thermogenics\\n\\nFirst off, if I'm not mist...     13   \n",
       "14  Re: Gamma Ray Bursters.  WHere  are they.\\n\\nI...     14   \n",
       "15  Internet resources\\n\\nI am taking a course ent...     14   \n",
       "\n",
       "            Class Name           Prediction  \n",
       "0            rec.autos            rec.autos  \n",
       "1            rec.autos            rec.autos  \n",
       "2      rec.motorcycles      rec.motorcycles  \n",
       "3      rec.motorcycles         alt.fan.dogs  \n",
       "4   rec.sport.baseball   rec.sport.baseball  \n",
       "5   rec.sport.baseball  rec.sports.baseball  \n",
       "6     rec.sport.hockey     rec.sport.hockey  \n",
       "7     rec.sport.hockey              (error)  \n",
       "8            sci.crypt   talk.politics.guns  \n",
       "9            sci.crypt              (error)  \n",
       "10     sci.electronics     rec.autos.makers  \n",
       "11     sci.electronics     rec.autos.makers  \n",
       "12             sci.med              (error)  \n",
       "13             sci.med              (error)  \n",
       "14           sci.space            sci.space  \n",
       "15           sci.space            sci.space  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53b96c",
   "metadata": {},
   "source": [
    "Tune Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "717a894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing tuned model to reuse.\n",
      "tunedModels/newsgroup-classification-model-mt0dnzoz9\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Iterable \n",
    "import random\n",
    "\n",
    "# Convert the data frame into a dataset suitable for tuning.\n",
    "input_data = {'examples': \n",
    "    df_train[['Text', 'Class Name']]\n",
    "      .rename(columns={'Text': 'textInput', 'Class Name': 'output'})\n",
    "      .to_dict(orient='records')\n",
    " }\n",
    "\n",
    "# If you are re-running this lab, add your model_id here.\n",
    "model_id = None\n",
    "\n",
    "# Or try and find a recent tuning job.\n",
    "if not model_id:\n",
    "  queued_model = None\n",
    "  # Newest models first.\n",
    "  for m in reversed(client.tunings.list()):\n",
    "    # Only look at newsgroup classification models.\n",
    "    if m.name.startswith('tunedModels/newsgroup-classification-model'):\n",
    "      # If there is a completed model, use the first (newest) one.\n",
    "      if m.state.name == 'JOB_STATE_SUCCEEDED':\n",
    "        model_id = m.name\n",
    "        print('Found existing tuned model to reuse.')\n",
    "        break\n",
    "\n",
    "      elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n",
    "        # If there's a model still queued, remember the most recent one.\n",
    "        queued_model = m.name\n",
    "  else:\n",
    "    if queued_model:\n",
    "      model_id = queued_model\n",
    "      print('Found queued model, still waiting.')\n",
    "\n",
    "\n",
    "# Upload the training data and queue the tuning job.\n",
    "if not model_id:\n",
    "    tuning_op = client.tunings.tune(\n",
    "        base_model=\"models/gemini-1.5-flash-001-tuning\",\n",
    "        training_dataset=input_data,\n",
    "        config=types.CreateTuningJobConfig(\n",
    "            tuned_model_display_name=\"Newsgroup classification model\",\n",
    "            batch_size=16,\n",
    "            epoch_count=2,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    print(tuning_op.state)\n",
    "    model_id = tuning_op.name\n",
    "\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "560b3f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! The model state is: JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "MAX_WAIT = datetime.timedelta(minutes=10)\n",
    "\n",
    "while not (tuned_model := client.tunings.get(name = model_id)).has_ended:\n",
    "\n",
    "    print(tuned_model.state)\n",
    "    time.sleep(60)\n",
    "\n",
    "    if datetime.datetime.now(datetime.timezone.utc) - tuned_model.create_time > MAX_WAIT:\n",
    "        print(\"Taking a shortcut, using a previously prepared model.\")\n",
    "        model_id = \"tunedModels/newsgroup-classification-model-ltenbi1b\"\n",
    "        tuned_model = client.tunings.get(name=model_id)\n",
    "        break\n",
    "\n",
    "print(f\"Done! The model state is: {tuned_model.state.name}\")\n",
    "\n",
    "if not tuned_model.has_succeeded and tuned_model.error:\n",
    "    print(\"Error:\", tuned_model.error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d5c799",
   "metadata": {},
   "source": [
    "Use the new Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a43dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n"
     ]
    }
   ],
   "source": [
    "new_text = \"\"\"\n",
    "First-timer looking to get out of here.\n",
    "\n",
    "Hi, I'm writing about my interest in travelling to the outer limits!\n",
    "\n",
    "What kind of craft can I buy? What is easiest to access from this 3rd rock?\n",
    "\n",
    "Let me know how to do that please.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=model_id, contents=new_text)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4019292f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d823da411748b1957410692e32e7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.50%\n"
     ]
    }
   ],
   "source": [
    "@retry.Retry(predicate=is_retriable)\n",
    "def classify_text(text: str) -> str:\n",
    "    \"\"\"Classify the provided text into a known newsgroup.\"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=model_id, contents=text)\n",
    "    rc = response.candidates[0]\n",
    "\n",
    "    # Any errors, filters, recitation, etc we can mark as a general error\n",
    "    if rc.finish_reason.name != \"STOP\":\n",
    "        return \"(error)\"\n",
    "    else:\n",
    "        return rc.content.parts[0].text\n",
    "\n",
    "\n",
    "# The sampling here is just to minimise your quota usage. If you can, you should\n",
    "# evaluate the whole test set with `df_model_eval = df_test.copy()`.\n",
    "df_model_eval = sample_data(df_test, 4, '.*')\n",
    "\n",
    "df_model_eval[\"Prediction\"] = df_model_eval[\"Text\"].progress_apply(classify_text)\n",
    "\n",
    "accuracy = (df_model_eval[\"Class Name\"] == df_model_eval[\"Prediction\"]).sum() / len(df_model_eval)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003759b",
   "metadata": {},
   "source": [
    "Token Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c020d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System instructed baseline model: 172 (input)\n",
      "Tuned model: 136 (input)\n",
      "Token savings: 26.47%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the *input* cost of the baseline model with system instructions.\n",
    "sysint_tokens = client.models.count_tokens(\n",
    "    model='gemini-1.5-flash-001', contents=[system_instruct, sample_row]\n",
    ").total_tokens\n",
    "print(f'System instructed baseline model: {sysint_tokens} (input)')\n",
    "\n",
    "# Calculate the input cost of the tuned model.\n",
    "tuned_tokens = client.models.count_tokens(model=tuned_model.base_model, contents=sample_row).total_tokens\n",
    "print(f'Tuned model: {tuned_tokens} (input)')\n",
    "\n",
    "savings = (sysint_tokens - tuned_tokens) / tuned_tokens\n",
    "print(f'Token savings: {savings:.2%}')  # Note that this is only n=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1314774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (verbose) output tokens: 141\n",
      "Tuned output tokens: 4\n"
     ]
    }
   ],
   "source": [
    "baseline_token_output = baseline_response.usage_metadata.candidates_token_count\n",
    "print('Baseline (verbose) output tokens:', baseline_token_output)\n",
    "\n",
    "tuned_model_output = client.models.generate_content(\n",
    "    model=model_id, contents=sample_row)\n",
    "tuned_tokens_output = tuned_model_output.usage_metadata.candidates_token_count\n",
    "print('Tuned output tokens:', tuned_tokens_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
